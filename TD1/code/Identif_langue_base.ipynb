{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "def ouvrir(path):\n",
    "  f = open(path, encoding=\"utf-8\")\n",
    "  ch = f.read()\n",
    "  f.close()\n",
    "  return ch\n",
    "\n",
    "dic = {}\n",
    "for path in glob.glob(\"corpus_multi/*/appr/*\"):#ch\n",
    "  toto, lg, titi, filename = re.split(\"\\\\\\\\\", path)#pour mac/linux: re.split(\"/\"...\n",
    "  dic.setdefault(lg, {})\n",
    "  chaine = ouvrir(path)\n",
    "  mots = chaine.split()\n",
    "  for m in mots:\n",
    "    dic[lg].setdefault(m, 0)\n",
    "    dic[lg][m]+=1\n",
    "\n",
    "models = {}\n",
    "for lg, dic_mots in dic.items():\n",
    "  L= []\n",
    "  for mot, effectif in dic_mots.items():\n",
    "    L.append([effectif, mot])\n",
    "  toto = sorted(L, reverse=True)[:10]\n",
    "  toto = [mot for effectif, mot in toto]    \n",
    "  models[lg] = toto\n",
    "\n",
    "w = open(\"models\", \"w\", encoding = \"utf-8\")\n",
    "w.write(str(models))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"models\", encoding=\"utf-8\")\n",
    "dic_models = eval(f.read())\n",
    "f.close()\n",
    "\n",
    "diagnostics = []\n",
    "for path in glob.glob(\"corpus_multi/*/test/*\"):\n",
    "  dic_mots = {}\n",
    "  toto, lg_text, titi, filename = re.split(\"\\\\\\\\\", path)#pour mac/linux: re.split(\"/\"...\n",
    "  chaine = ouvrir(path)\n",
    "  mots = chaine.split()\n",
    "  for m in mots:\n",
    "    dic_mots.setdefault(m, 0)\n",
    "    dic_mots[m]+=1\n",
    "  L= []\n",
    "  for mot, effectif in dic_mots.items():\n",
    "    L.append([effectif, mot])\n",
    "  toto = sorted(L, reverse=True)[:10]\n",
    "  toto = [mot for effectif, mot in toto]\n",
    "  liste_predictions = []\n",
    "  for lg_model, most_frequent in dic_models.items():\n",
    "    taille_intersection = len(set(toto).intersection(set(most_frequent)))\n",
    "    liste_predictions.append([taille_intersection, lg_model])\n",
    "  diagnostics.append([lg_text, sorted(liste_predictions, reverse=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreurs de prédiction :\n",
      "bg\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "cs\n",
      "[[6, 'sk'], [6, 'cs'], [3, 'sl']]\n",
      "cs\n",
      "[[6, 'sk'], [6, 'cs'], [4, 'sl']]\n",
      "cs\n",
      "[[5, 'sk'], [5, 'cs'], [3, 'sl']]\n",
      "cs\n",
      "[[4, 'sk'], [3, 'cs'], [2, 'pt']]\n",
      "cs\n",
      "[[2, 'sk'], [2, 'cs'], [1, 'sl']]\n",
      "cs\n",
      "[[3, 'sl'], [3, 'sk'], [3, 'cs']]\n",
      "cs\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "cs\n",
      "[[4, 'sk'], [4, 'cs'], [2, 'sl']]\n",
      "cs\n",
      "[[5, 'sk'], [5, 'cs'], [3, 'sl']]\n",
      "cs\n",
      "[[2, 'sk'], [2, 'pt'], [2, 'pl']]\n",
      "cs\n",
      "[[3, 'en'], [2, 'sl'], [2, 'sk']]\n",
      "da\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "de\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "el\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "es\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "et\n",
      "[[2, 'fi'], [2, 'et'], [1, 'en']]\n",
      "et\n",
      "[[2, 'fi'], [2, 'et'], [1, 'en']]\n",
      "et\n",
      "[[2, 'fi'], [2, 'et'], [2, 'en']]\n",
      "et\n",
      "[[3, 'fi'], [3, 'et'], [3, 'en']]\n",
      "et\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "et\n",
      "[[2, 'fi'], [2, 'et'], [1, 'en']]\n",
      "et\n",
      "[[2, 'fi'], [2, 'et'], [1, 'en']]\n",
      "fi\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "fr\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "hu\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "it\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "lt\n",
      "[[1, 'ro'], [1, 'pt'], [1, 'nl']]\n",
      "lt\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "lv\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "mt\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "nl\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "pl\n",
      "[[1, 'ro'], [1, 'pt'], [1, 'pl']]\n",
      "pl\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "pt\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "ro\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "sk\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "sl\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n",
      "sv\n",
      "[[8, 'en'], [3, 'fi'], [3, 'et']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Erreurs de prédiction (langue suivi du podium des intersections):\")\n",
    "for lg_text, predictions in diagnostics:\n",
    "    lg_pred = predictions[0][1]\n",
    "    if lg_text!=lg_pred:\n",
    "      print(lg_text)\n",
    "      print(predictions[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
