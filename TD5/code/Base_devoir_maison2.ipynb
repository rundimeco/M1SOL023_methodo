{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "## récupérer les données\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(\"DATA/Corpus_rapv2.xml\")\n",
    "root = tree.getroot()\n",
    "liste_artistes = []\n",
    "liste_paroles = []\n",
    "liste_titres = []\n",
    "for child in root:##\n",
    "    artiste = child.get(\"artiste\")\n",
    "    liste_artistes.append(artiste)\n",
    "    liste_titres.append(child.get(\"titre\"))\n",
    "    \n",
    "for chanson in root.findall(\"chanson\"):\n",
    "    paroles = chanson.find(\"paroles\")\n",
    "    liste_paroles.append(paroles.text)\n",
    "    \n",
    "print(len(liste_paroles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "##focntions de pré-traitement et d'évaluation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "\n",
    "def remove_stopwords(chaine):\n",
    "  final_stopwords_list =stopwords.words('french')\n",
    "  s = chaine\n",
    "  for stopword in final_stopwords_list:\n",
    "    chaine = re.sub(f\" {stopword} \", \" \", chaine)\n",
    "  return chaine\n",
    "\n",
    "def remove_ponctuation(chaine):\n",
    "  ponctuations = [\",\", \"'\", '\"', \"-\", \"\\.\"]\n",
    "  for stopword in ponctuations:\n",
    "    chaine = re.sub(f\" {stopword} \", \" \", chaine)\n",
    "  return chaine\n",
    "\n",
    "def resultats_par_classe(y_test, y_pred):\n",
    "  dic_resultats = {} #pour recenser les erreurs et les bonnnes prédictions\n",
    "  for artiste in set(y_test):\n",
    "    dic_resultats[artiste] = {\"VP\":0, \"FP\":0, \"FN\":0}\n",
    "    \n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == y_pred[i]:#vrai positif\n",
    "        dic_resultats[y_test[i]][\"VP\"]+=1#on ajoute 1, équivalent à :\n",
    "    else:\n",
    "        dic_resultats[y_test[i]][\"FN\"]+=1 # Il en manque un ici (FN)\n",
    "        dic_resultats[y_pred[i]][\"FP\"]+=1 # Il y en a un de trop là (FP)\n",
    "  return dic_resultats  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "liste_chansons = []\n",
    "for i in range(len(liste_titres)):\n",
    "    chanson = liste_titres[i] +\"\\n\"+liste_paroles[i]\n",
    "    liste_chansons.append(chanson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92i Veyron\n",
      "\n",
      "[Intro]\n",
      "Personne, personne\n",
      "Personne, personne\n",
      "\n",
      "[Couplet 1]\n",
      "Nouveau riche, ma Lamborghini a pris quelques dos-d'âne\n",
      "J'fais ni la queue au Ritz, ni au McDonald's\n",
      "Si c'est eux qui ont raison, je n'suis pas raisonnable\n",
      "La rafale dans ton salon sera sûrement désagréable\n",
      "Nouveau riche, ma Lamborghini a pris quelques dos-d'âne\n",
      "J'fais ni la queue au Ritz, ni au McDonald's\n",
      "Si c'est eux qui ont raison, je n'suis pas raisonnable\n",
      "La rafale dans ton salon sera sûrement désagréable\n",
      "\n",
      "[Refrain]\n",
      "On trinque à nos balafres, à nos crochets tous les soirs\n",
      "\"Noir c'est noir\", ont-ils dit, y'a donc vraiment plus d'espoir\n",
      "Les vainqueurs l'écrivent, les vaincus racontent l'histoire\n",
      "Les vainqueurs l'écrivent, les vaincus racontent l'histoire\n",
      "Personne dans le monde ne marche du même pas\n",
      "Leurs règles ont toutes une tombe, c'est ça qu'ils n'comprennent pas\n",
      "Des allers-retours en prison, certains n'en reviennent pas\n",
      "J'ai une kalash et des mouftons, tous sous le même toit\n",
      "Toujours d'humeur à les lever, que l'avenir suce mon troisième doigt\n",
      "Non, moi je n't'aime pas, ni celui qui est avec toi\n",
      "Y'a que quand tu baises ta daronne que j'suis de tout cœur avec toi\n",
      "T'as même pas de quoi me faire fumer, qu'est-ce que j'vais faire avec toi ?\n",
      "\n",
      "[Couplet 2]\n",
      "Je parle de rue car j'y ai baigné, même si j'y suis beaucoup moins\n",
      "Je t'écris du block avec G.A.T.O B.A.T.O, boug an mwen\n",
      "Y'a du son, d'la chatte, du shit, y'a le Nueve-2i dans le coin\n",
      "Grosse bite dans la chatte du SMIC, coup d'pied retourné dans le groin\n",
      "Bombe nucléaire sur le game, il ne restera que moi et les rats\n",
      "Quand j'monterai dans la Veyron, jamais tu n'me reverras\n",
      "Inspiré par la musique de ces descendants d'esclaves\n",
      "Ils achètent négros sur place publique, pour eux rien n'est grave\n",
      "J'ai couronne sur la tête pourtant c'est le voisin qui a eu la fève\n",
      "\"Il n'y aura jamais de trêve\" m'ont dit mes khos du 93\n",
      "Braisé poulet, locos, bananes, le rap c'est haram\n",
      "Génocide sur ces négros, j'vais les Boko Haram\n",
      "Ne fais pas trop de bien ou tu seras cloué sur une croix\n",
      "La rafale dans ta grand-mère arrivera plus tôt que tu n'crois\n",
      "La race humaine me dégoûte, j'allume gros pilon au chalumeau\n",
      "Nique ta fondation de merde, j'préfère sauver les animaux\n",
      "\n",
      "[Refrain]\n",
      "On trinque à nos balafres, à nos crochets tous les soirs\n",
      "\"Noir c'est noir\", ont-ils dit, y'a donc vraiment plus d'espoir\n",
      "Les vainqueurs l'écrivent, les vaincus racontent l'histoire\n",
      "Les vainqueurs l'écrivent, les vaincus racontent l'histoire\n",
      "Personne dans le monde ne marche du même pas\n",
      "Leurs règles ont toutes une tombe, c'est ça qu'ils n'comprennent pas\n",
      "Des allers-retours en prison, certains n'en reviennent pas\n",
      "J'ai une kalash et des mouftons, tous sous le même toit\n",
      "Toujours d'humeur à les lever, que l'avenir suce mon troisième doigt\n",
      "Non, moi je n't'aime pas ni celui qui est avec toi\n",
      "Y'a que quand tu baises ta daronne que j'suis de tout cœur avec toi\n",
      "T'as même pas de quoi me faire fumer, qu'est-ce que j'vais faire avec toi ?\n",
      "toto\n",
      "titi\n",
      "tutu\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-547aaac9b6fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliste_artistes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m### Vectoriser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "y = liste_artistes\n",
    "### Vectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "V = CountVectorizer(ngram_range = (1,3))\n",
    "\n",
    "for pretraitement in [\"stopwords\", \"e\", \"ponctuation\", \"None\"]:\n",
    "  if pretraitement ==\"stopwords\":\n",
    "    liste_titres_pretraite = [remove_stopwords(titre) for titre in liste_paroles]\n",
    "    X = V.fit_transform(liste_titres_pretraite)\n",
    "  elif pretraitement ==\"e\":\n",
    "    liste_titres_pretraite = [re.sub(\"e\", \"\", titre) for titre in liste_paroles]\n",
    "    X = V.fit_transform(liste_titres_pretraite)\n",
    "  elif pretraitement ==\"ponctuation\":\n",
    "    liste_titres_pretraite = [remove_ponctuation(titre) for titre in liste_paroles]\n",
    "    X = V.fit_transform(liste_titres_pretraite)    \n",
    "  else:\n",
    "    X = V.fit_transform(liste_paroles)\n",
    "  for split_size in [0.3]: #[0.1, 0.2, 0.3, 0.9]:\n",
    "    print(f\"Split_size : {split_size}, Pretraitement: {pretraitement}\")\n",
    "    #découpage train VS test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_size, random_state=0)\n",
    "    ##classification\n",
    "    ppn = Perceptron(eta0 = 0.1, random_state=0)\n",
    "    ppn.fit(X_train, y_train)\n",
    "    y_pred = ppn.predict(X_test)\n",
    "    print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    res_par_classe = resultats_par_classe(y_test, y_pred)\n",
    "    for classe, res in res_par_classe.items():\n",
    "        print(f\" {classe} : {res}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
